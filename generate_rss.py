from openai import OpenAI
from feedgen.feed import FeedGenerator
from datetime import datetime, timezone, timedelta
import os
import json
import random
import sys
import traceback
import uuid
import time

# ë””ë²„ê¹… í•¨ìˆ˜
def log(message):
    """ë¡œê·¸ ì¶œë ¥ í•¨ìˆ˜"""
    timestamp = datetime.now().strftime('%H:%M:%S')
    print(f"[{timestamp}] {message}")
    sys.stdout.flush()  # ì¦‰ì‹œ ì¶œë ¥ ë³´ì¥

# ìŠ¤í¬ë¦½íŠ¸ ì‹œì‘
log("ğŸš€ ê¿ˆí•´ëª½ RSS ìƒì„± ìŠ¤í¬ë¦½íŠ¸ ì‹œì‘")

# ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
os.makedirs("docs", exist_ok=True)
log("âœ… docs ë””ë ‰í† ë¦¬ í™•ì¸ ì™„ë£Œ")

# í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ í™•ì¸
log(f"ğŸ“‚ í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: {os.getcwd()}")
log(f"ğŸ“‚ ë””ë ‰í† ë¦¬ ë‚´ìš©: {os.listdir('.')}")

# OpenAI API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
try:
    client = OpenAI()
    log("âœ… OpenAI API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
    # API í‚¤ ì„¤ì • í™•ì¸
    key_set = os.environ.get("OPENAI_API_KEY") is not None
    log(f"ğŸ”‘ API í‚¤ ì„¤ì • ìƒíƒœ: {'ì„¤ì •ë¨' if key_set else 'ì„¤ì •ë˜ì§€ ì•ŠìŒ'}")
except Exception as e:
    log(f"âŒ OpenAI API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    traceback.print_exc()
    sys.exit(1)

# íŒŒì¼ ê²½ë¡œ ì„¤ì •
rss_file = "docs/rss.xml"
dream_keywords_file = "dream_keywords.json"
used_keywords_file = "used_keywords.json"

log(f"ğŸ“ RSS íŒŒì¼ ê²½ë¡œ: {rss_file}")
log(f"ğŸ“ í‚¤ì›Œë“œ íŒŒì¼ ê²½ë¡œ: {dream_keywords_file}")
log(f"ğŸ“ ì‚¬ìš©ëœ í‚¤ì›Œë“œ íŒŒì¼ ê²½ë¡œ: {used_keywords_file}")

# ì˜¤ëŠ˜ ë‚ ì§œ (í•œêµ­ ì‹œê°„ëŒ€ ê³ ë ¤)
KST = timezone(timedelta(hours=9))
now = datetime.now(KST)
today = now.strftime('%Y-%m-%d')
today_rfc822 = now.strftime('%a, %d %b %Y %H:%M:%S +0900')
timestamp = int(time.time())  # Unix íƒ€ì„ìŠ¤íƒ¬í”„ (ìºì‹œ ë°©ì§€ìš©)

log(f"ğŸ“… ì˜¤ëŠ˜ ë‚ ì§œ: {today} (KST)")
log(f"â±ï¸ íƒ€ì„ìŠ¤íƒ¬í”„: {timestamp}")

# ìºì‹œ ë°©ì§€ìš© ê³ ìœ  ID ìƒì„±
cache_buster = str(uuid.uuid4())[:8]
log(f"ğŸ”„ ìºì‹œ ë°©ì§€ ID: {cache_buster}")

# í‚¤ì›Œë“œ ëª©ë¡ ë¡œë“œ
try:
    with open(dream_keywords_file, "r", encoding="utf-8") as f:
        all_keywords = json.load(f)
    log(f"âœ… ì´ {len(all_keywords)}ê°œì˜ í‚¤ì›Œë“œë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
except Exception as e:
    log(f"âŒ í‚¤ì›Œë“œ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
    traceback.print_exc()
    log(f"í˜„ì¬ ë””ë ‰í† ë¦¬: {os.getcwd()}")
    log(f"íŒŒì¼ ëª©ë¡: {os.listdir('.')}")
    sys.exit(1)

# ì‚¬ìš©ëœ í‚¤ì›Œë“œ ë¡œë“œ
used_keywords = []
if os.path.exists(used_keywords_file):
    try:
        with open(used_keywords_file, "r", encoding="utf-8") as f:
            content = f.read().strip()
            if content:  # ë‚´ìš©ì´ ìˆëŠ” ê²½ìš°ì—ë§Œ íŒŒì‹±
                used_keywords = json.loads(content)
            else:
                log("âš ï¸ ì‚¬ìš©ëœ í‚¤ì›Œë“œ íŒŒì¼ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ìƒˆë¡œ ì‹œì‘í•©ë‹ˆë‹¤.")
        log(f"â„¹ï¸ ì§€ê¸ˆê¹Œì§€ {len(used_keywords)}ê°œì˜ í‚¤ì›Œë“œê°€ ì‚¬ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except json.JSONDecodeError as e:
        log(f"âš ï¸ ì‚¬ìš©ëœ í‚¤ì›Œë“œ íŒŒì¼ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        log(f"íŒŒì¼ ë‚´ìš©: {open(used_keywords_file, 'r').read()}")
        used_keywords = []
    except Exception as e:
        log(f"âš ï¸ ì‚¬ìš©ëœ í‚¤ì›Œë“œ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨, ìƒˆë¡œ ì‹œì‘í•©ë‹ˆë‹¤: {e}")
        used_keywords = []
else:
    log("â„¹ï¸ ì‚¬ìš©ëœ í‚¤ì›Œë“œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")

# ë¯¸ì‚¬ìš© í‚¤ì›Œë“œ í•„í„°ë§
unused_keywords = [kw for kw in all_keywords if kw not in used_keywords]
log(f"â„¹ï¸ ë¯¸ì‚¬ìš© í‚¤ì›Œë“œ ìˆ˜: {len(unused_keywords)}")

if len(unused_keywords) < 3:
    log("â„¹ï¸ ë¯¸ì‚¬ìš© í‚¤ì›Œë“œê°€ ë¶€ì¡±í•˜ì—¬ ëª¨ë“  í‚¤ì›Œë“œë¥¼ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤.")
    used_keywords = []  # ì´ˆê¸°í™”
    unused_keywords = all_keywords.copy()

# 3ê°œ í‚¤ì›Œë“œ ì„ íƒ
picked = random.sample(unused_keywords, 3)
log(f"ğŸ² ì˜¤ëŠ˜ì˜ ì„ íƒ í‚¤ì›Œë“œ: {', '.join(picked)}")

# í‚¤ì›Œë“œ ë³„ ê¿ˆí•´ëª½ ìƒì„±
dreams = []
for i, keyword in enumerate(picked, 1):
    try:
        prompt = f"'{keyword}' ê¿ˆì— ëŒ€í•œ í•´ëª½ì„ 3~4ë¬¸ì¥ìœ¼ë¡œ ì•ì— ìŠ¤ë ˆë“œ ê°ì„±ìœ¼ë¡œ ë°˜ë§ë¡œ ì˜í’€ì–´ì„œ ì„¤ëª…í•´ì¤˜."
        log(f"ğŸ“ '{keyword}' í‚¤ì›Œë“œì— ëŒ€í•œ í•´ëª½ ìƒì„± ì¤‘...")
        
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=300
        )
        
        text = response.choices[0].message.content.strip()
        dreams.append((keyword, text))
        used_keywords.append(keyword)
        log(f"âœ… ìƒì„± ì™„ë£Œ ({i}/3): {text[:50]}...")
    except Exception as e:
        log(f"âŒ '{keyword}' í•´ëª½ ìƒì„± ì‹¤íŒ¨: {e}")
        traceback.print_exc()

# ê¸°ì¡´ RSS í•­ëª© ë¡œë“œ
existing_entries = []
try:
    if os.path.exists(rss_file):
        log("ğŸ“‚ ê¸°ì¡´ RSS íŒŒì¼ ì½ê¸° ì‹œë„ ì¤‘...")
        import xml.etree.ElementTree as ET
        
        try:
            tree = ET.parse(rss_file)
            root = tree.getroot()
            channel = root.find('channel')
            
            if channel is not None:
                items = channel.findall('item')
                log(f"ğŸ” ê¸°ì¡´ í•­ëª© {len(items)}ê°œ ë°œê²¬")
                
                for item in items:
                    title = item.find('title')
                    if title is not None and not title.text.startswith(today):
                        link = item.find('link')
                        desc = item.find('description')
                        pubdate = item.find('pubDate')
                        
                        if all([title, link, desc, pubdate]):
                            existing_entries.append({
                                'title': title.text,
                                'link': link.text,
                                'description': desc.text,
                                'pubDate': pubdate.text
                            })
                            
                log(f"âœ… {len(existing_entries)}ê°œì˜ ì´ì „ í•­ëª©ì„ ìœ ì§€í•©ë‹ˆë‹¤.")
        except ET.ParseError as e:
            log(f"âš ï¸ XML íŒŒì‹± ì‹¤íŒ¨: {e}")
            log("âš ï¸ ê¸°ì¡´ RSS íŒŒì¼ ë‚´ìš©ì„ ì½ì–´ ì˜¤ë¥˜ í™•ì¸:")
            with open(rss_file, 'r', encoding='utf-8') as f:
                log(f.read()[:500] + "...")  # ì²˜ìŒ 500ìë§Œ í‘œì‹œ
    else:
        log("ğŸ“‚ ê¸°ì¡´ RSS íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
except Exception as e:
    log(f"âš ï¸ ê¸°ì¡´ RSS íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    traceback.print_exc()
    log("âš ï¸ ìƒˆ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.")

# RSS í”¼ë“œ ìƒì„±
try:
    if len(dreams) == 0:
        log("âš ï¸ ìƒì„±ëœ ê¿ˆí•´ëª½ì´ ì—†ìŠµë‹ˆë‹¤. RSS í”¼ë“œë¥¼ ì—…ë°ì´íŠ¸í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        sys.exit(1)
        
    log("ğŸ”„ RSS í”¼ë“œ ìƒì„± ì‹œì‘...")
    fg = FeedGenerator()
    fg.title('ê²ì´ì¸ ì˜ ê¿ˆí•´ëª½ í”¼ë“œ')
    
    # ìºì‹œ ë°©ì§€ë¥¼ ìœ„í•œ ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°ê°€ í¬í•¨ëœ ë§í¬
    fg.link(href=f'https://shyunki.github.io/dream-rss-feed/rss.xml?v={timestamp}')
    
    # íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ ì„¤ëª…ì— ë³€ê²½ì‚¬í•­ ì¶”ê°€
    fg.description(f'ë§¤ì¼ 3ê°œì˜ ê¿ˆ í‚¤ì›Œë“œì— ëŒ€í•œ í’ë¶€í•œ í•´ëª½ì„ ì œê³µí•©ë‹ˆë‹¤. (ì—…ë°ì´íŠ¸: {today})')
    fg.language('ko-kr')
    
    # ë§¤ë²ˆ ì—…ë°ì´íŠ¸ë˜ëŠ” pubDate
    fg.pubDate(today_rfc822)
    
    # ìºì‹œ ë°©ì§€ìš© ê³ ìœ  íƒœê·¸ ì¶”ê°€
    fg.generator(f'Dream RSS Generator {cache_buster}')
    
    # ìƒˆ í•­ëª© ì¶”ê°€
    for i, (kw, desc) in enumerate(dreams, 1):
        fe = fg.add_entry()
        fe.title(f"{today} ğŸŒ™ {kw} ê¿ˆ")
        # ìºì‹œ ë°©ì§€ë¥¼ ìœ„í•´ íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€
        fe.link(href=f'https://shyunki.github.io/dream-rss-feed/rss.xml#{i}_{timestamp}')
        fe.description(desc)
        fe.pubDate(today_rfc822)
        # ê³ ìœ  ID ì¶”ê°€
        fe.id(f'https://shyunki.github.io/dream-rss-feed/dream/{kw}_{timestamp}_{cache_buster}')
        log(f"â• RSS í•­ëª© ì¶”ê°€: {kw}")
    
    # ê¸°ì¡´ í•­ëª© ì¶”ê°€ (ìµœëŒ€ 30ê°œë§Œ ìœ ì§€)
    max_old_entries = 30 - len(dreams)
    for i, entry in enumerate(existing_entries[:max_old_entries]):
        fe = fg.add_entry()
        fe.title(entry['title'])
        fe.link(href=entry['link'])
        fe.description(entry['description'])
        fe.pubDate(entry['pubDate'])
        log(f"â• ê¸°ì¡´ RSS í•­ëª© ìœ ì§€: {entry['title'][:30]}...")
    
    # RSS íŒŒì¼ ì €ì¥
    fg.rss_file(rss_file)
    log(f"âœ… RSS í”¼ë“œê°€ {rss_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # HTML ë¦¬ë‹¤ì´ë ‰íŠ¸ í˜ì´ì§€ ìƒì„± (ì„ íƒì )
    html_file = "docs/index.html"
    with open(html_file, "w", encoding="utf-8") as f:
        f.write(f"""<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta http-equiv="refresh" content="0;url=./rss.xml?v={timestamp}">
    <title>ê²ì´ì¸ ì˜ ê¿ˆí•´ëª½ í”¼ë“œ</title>
</head>
<body>
    <h1>ê²ì´ì¸ ì˜ ê¿ˆí•´ëª½ í”¼ë“œ</h1>
    <p>RSS í”¼ë“œë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸ë©ë‹ˆë‹¤. ìë™ìœ¼ë¡œ ì´ë™í•˜ì§€ ì•Šìœ¼ë©´ <a href="./rss.xml?v={timestamp}">ì—¬ê¸°</a>ë¥¼ í´ë¦­í•˜ì„¸ìš”.</p>
    <p>ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {today}</p>
</body>
</html>""")
    log(f"âœ… HTML ë¦¬ë‹¤ì´ë ‰íŠ¸ í˜ì´ì§€ê°€ {html_file}ì— ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # RSS íŒŒì¼ ë‚´ìš© í™•ì¸
    if os.path.exists(rss_file):
        file_size = os.path.getsize(rss_file)
        log(f"ğŸ“„ RSS íŒŒì¼ í¬ê¸°: {file_size} ë°”ì´íŠ¸")
        if file_size > 0:
            with open(rss_file, 'r', encoding='utf-8') as f:
                content = f.read(200)  # ì²˜ìŒ 200ìë§Œ í‘œì‹œ
                log(f"ğŸ“„ RSS íŒŒì¼ ì‹œì‘ ë¶€ë¶„: {content}...")
        else:
            log("âš ï¸ RSS íŒŒì¼ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤!")
    
    # ì‚¬ìš©ëœ í‚¤ì›Œë“œ ì €ì¥
    try:
        with open(used_keywords_file, "w", encoding="utf-8") as f:
            # ì¤‘ë³µ ì œê±°í•˜ì—¬ ì €ì¥
            unique_used_keywords = list(set(used_keywords))
            json.dump(unique_used_keywords, f, ensure_ascii=False, indent=2)
        log(f"âœ… ì‚¬ìš©ëœ í‚¤ì›Œë“œ ëª©ë¡ì´ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤ (ì´ {len(set(used_keywords))}ê°œ)")
        
        # íŒŒì¼ ë‚´ìš© í™•ì¸
        with open(used_keywords_file, "r", encoding="utf-8") as f:
            content = f.read()
        log(f"ğŸ“„ ì‚¬ìš©ëœ í‚¤ì›Œë“œ íŒŒì¼ ë‚´ìš© í™•ì¸: {content[:100]}...")
    except Exception as e:
        log(f"âŒ ì‚¬ìš©ëœ í‚¤ì›Œë“œ ì €ì¥ ì‹¤íŒ¨: {e}")
        traceback.print_exc()
    
    # í•­ìƒ ë³€ê²½ì‚¬í•­ì´ ìˆë„ë¡ ë”ë¯¸ íŒŒì¼ ìƒì„±
    dummy_file = "docs/last_update.txt"
    with open(dummy_file, "w", encoding="utf-8") as f:
        f.write(f"Last updated: {today} {datetime.now().strftime('%H:%M:%S')}\nCache buster: {cache_buster}\n")
    log(f"âœ… ì—…ë°ì´íŠ¸ íƒ€ì„ìŠ¤íƒ¬í”„ íŒŒì¼ ìƒì„± ì™„ë£Œ")
    
    log("ğŸ‰ ëª¨ë“  ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
except Exception as e:
    log(f"âŒ RSS í”¼ë“œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    traceback.print_exc()
    sys.exit(1)
